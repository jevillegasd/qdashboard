#!/usr/bin/env python3
"""
QDashboard - Quantum Computing Dashboard

A professional quantum computing dashboard with file browsing, experiment monitoring, 
QPU status tracking, and report visualization capabilities.

File server functionality based on flask-file-server by Wildog:
https://github.com/Wildog/flask-file-server

Extended with quantum computing specific features:
- QPU status monitoring and SLURM integration
- Real-time package version tracking (qibo, qibolab, qibocal)
- Enhanced report rendering with Plotly support
- Dark theme optimized for quantum computing workflows
"""

from flask import Flask, make_response, request, session, render_template, send_file, Response, jsonify
from flask.views import MethodView
from werkzeug.utils import secure_filename
from datetime import datetime
import humanize
import os
import re
import stat
import json
import mimetypes
import sys
import subprocess
import traceback
import importlib.metadata
import pkg_resources
import inspect
from pathlib2 import Path
import numpy as np
try:
    import rustworkx as rx
    from rustworkx.visualization import mpl_draw
    HAS_RUSTWORKX = True
except ImportError:
    HAS_RUSTWORKX = False
    print("Warning: rustworkx not available. Topology detection will be limited.")

try:
    import matplotlib
    matplotlib.use('Agg')  # Use non-interactive backend
    import matplotlib.pyplot as plt
    HAS_MATPLOTLIB = True
except ImportError:
    HAS_MATPLOTLIB = False
    print("Warning: matplotlib not available. Topology visualization will be limited.")

import base64
import io

PORT_NUMBER=5005
home_path = os.environ.get('HOME')
user = os.environ.get('USER')
host, port, root = "127.0.0.1", PORT_NUMBER, os.path.normpath(home_path)
app = Flask(__name__, static_url_path='/assets', static_folder='assets')
app.config['APPLICATION_NAME'] = 'QDashboard'
key = ""

ignored = ['.bzr', '$RECYCLE.BIN', '.DAV', '.DS_Store', '.git', '.hg', '.htaccess', '.htpasswd', '.Spotlight-V100', '.svn', '__MACOSX', 'ehthumbs.db', 'robots.txt', 'Thumbs.db', 'thumbs.tps']
datatypes = {'audio': 'm4a,mp3,oga,ogg,webma,wav', 'archive': '7z,zip,rar,gz,tar,npz', 'image': 'gif,ico,jpe,jpeg,jpg,png,svg,webp', 'pdf': 'pdf', 'quicktime': '3g2,3gp,3gp2,3gpp,mov,qt', 'source': 'atom,bat,bash,c,cmd,coffee,css,hml,js,json,java,less,markdown,md,php,pl,py,rb,rss,sass,scpt,swift,scss,sh,xml,yml,plist', 'text': 'txt', 'video': 'mp4,m4v,ogv,webm', 'website': 'htm,html,mhtm,mhtml,xhtm,xhtml'}
icontypes = {'fa-music': 'm4a,mp3,oga,ogg,webma,wav', 'fa-archive': '7z,zip,rar,gz,tar', 'fa-picture-o': 'gif,ico,jpe,jpeg,jpg,png,svg,webp', 'fa-file-text': 'pdf', 'fa-film': '3g2,3gp,3gp2,3gpp,mov,qt', 'fa-code': 'atom,plist,bat,bash,c,cmd,coffee,css,hml,js,json,java,less,markdown,md,php,pl,py,rb,rss,sass,scpt,swift,scss,sh,xml,yml', 'fa-file-text-o': 'txt', 'fa-film': 'mp4,m4v,ogv,webm', 'fa-globe': 'htm,html,mhtm,mhtml,xhtm,xhtml'}

@app.template_filter('size_fmt')
def size_fmt(size):
    return humanize.naturalsize(size)

@app.template_filter('time_fmt')
def time_desc(timestamp):
    mdate = datetime.fromtimestamp(timestamp)
    str = mdate.strftime('%Y-%m-%d %H:%M:%S')
    return str

@app.template_filter('data_fmt')
def data_fmt(filename):
    t = 'unknown'
    for type, exts in datatypes.items():
        if filename.split('.')[-1] in exts:
            t = type
    return t

@app.template_filter('icon_fmt')
def icon_fmt(filename):
    i = 'fa-file-o'
    for icon, exts in icontypes.items():
        if filename.split('.')[-1] in exts:
            i = icon
    return i

@app.template_filter('humanize')
def time_humanize(timestamp):
    mdate = datetime.utcfromtimestamp(timestamp)
    return humanize.naturaltime(mdate)




def get_type(mode):
    if stat.S_ISDIR(mode) or stat.S_ISLNK(mode):
        type = 'dir'
    else:
        type = 'file'
    return type

def partial_response(path, start, end=None):
    file_size = os.path.getsize(path)

    if end is None:
        end = file_size - start - 1
    end = min(end, file_size - 1)
    length = end - start + 1

    with open(path, 'rb') as fd:
        fd.seek(start)
        bytes = fd.read(length)
    assert len(bytes) == length

    response = Response(
        bytes,
        206,
        mimetype=mimetypes.guess_type(path)[0],
        direct_passthrough=True,
    )
    response.headers.add(
        'Content-Range', 'bytes {0}-{1}/{2}'.format(
            start, end, file_size,
        ),
    )
    response.headers.add(
        'Accept-Ranges', 'bytes'
    )
    return response

def get_range(request):
    range = request.headers.get('Range')
    m = re.match('bytes=(?P<start>\d+)-(?P<end>\d+)?', range)
    if m:
        start = m.group('start')
        end = m.group('end')
        start = int(start)
        if end is not None:
            end = int(end)
        return start, end
    else:
        return 0, None


@app.route("/")
def dashboard():
    """
    Main dashboard route - QDashboard extension
    
    Displays quantum computing specific metrics including:
    - QPU health and availability 
    - Package versions (qibo, qibolab, qibocal)
    - SLURM queue status and logs
    
    This extends the original flask-file-server with quantum computing dashboard
    """
    qpu_health = get_qpu_health()
    available_qpus = get_available_qpus()
    qibo_versions = get_qibo_versions()
    slurm_queue_status = get_slurm_status()
    last_slurm_log = get_slurm_output()
    return render_template('dashboard.html',
                           qpu_health=qpu_health,
                           available_qpus=available_qpus,
                           qibo_versions=qibo_versions,
                           slurm_queue_status=slurm_queue_status,
                           last_slurm_log=last_slurm_log)

def get_qpu_health():
    # Placeholder
    return "N/A"

def get_available_qpus():
    qrc_path = os.environ.get('QIBOLAB_PLATFORMS', os.path.join(root, 'qibolab_platforms_qrc'))
    
    # Check if platforms directory exists
    if not os.path.exists(qrc_path):
        return "N/A"
    
    try:
        with open(os.path.join(qrc_path, 'queues.json'), 'r') as f:
            queues = json.load(f)
    except (IOError, json.JSONDecodeError):
        queues = {}
    
    total_qpus = 0
    online_qpus = 0
    
    try:
        for qpu_name in os.listdir(qrc_path):
            qpu_path = os.path.join(qrc_path, qpu_name)
            if os.path.isdir(qpu_path) and not qpu_name.startswith('.'):
                total_qpus += 1
                
                # Check if QPU is online
                queue_name = queues.get(qpu_name, 'N/A')
                if queue_name != 'N/A':
                    try:
                        sinfo_output = subprocess.check_output(['sinfo', '-p', queue_name]).decode()
                        if queue_name in sinfo_output:
                            online_qpus += 1
                    except (subprocess.CalledProcessError, FileNotFoundError):
                        pass # Keep as offline if sinfo fails or queue not found
    except OSError:
        return "N/A"
    
    return f"{online_qpus} / {total_qpus}"

def get_qibo_versions():
    """Get versions of qibo, qibolab, and qibocal packages"""
    versions = {}
    packages = ['qibo', 'qibolab', 'qibocal']
    
    for package in packages:
        try:
            import importlib.metadata
            version = importlib.metadata.version(package)
            versions[package] = version
        except ImportError:
            # Fallback for older Python versions
            try:
                import pkg_resources
                version = pkg_resources.get_distribution(package).version
                versions[package] = version
            except (pkg_resources.DistributionNotFound, ImportError):
                versions[package] = "Not installed"
        except Exception:
            versions[package] = "Unknown"
    
    return versions

"""Submit a job to the SLURM queue"""
@app.route("/qqsubmit")
def qqsubmit():
     qpu = request.args.get('qpu')
     import subprocess
     os_process = subprocess.Popen(["bash",root+"/work/qqsubmit.sh",home_path,qpu],
                               stdout=subprocess.PIPE, stderr=subprocess.PIPE)
     stdout, stderr = os_process.communicate()
     
     out_string = stdout.decode('utf-8').replace('\n','<br>')
     return render_template('job_submission.html', output_content=out_string)

@app.route("/latest")
def latest():    
    with open(home_path+"/.latest", 'r') as file:  # r to open file in READ mode
        report_path = file.read().rstrip()

    try:
        res = report_viewer(report_path)
    except FileNotFoundError as e:
        last_path = report_path.rstrip().replace(root,'')
        
        # Parse SLURM log for error information
        has_error, error_message = parse_slurm_log_for_errors()
        
        res = make_response(render_template('latest_not_found.html',
                                            last_path=last_path,
                                            slurm_queue_status=get_slurm_status(),
                                            last_slurm_log=get_slurm_output(),
                                            has_error=has_error,
                                            error_message=error_message), 201)
    except Exception as e:
        raise(e)
    
    return res

@app.route("/report_assets/<path:filename>")
def report_assets(filename):
    """Serve assets from the latest report directory"""
    try:
        with open(home_path+"/.latest", 'r') as file:
            report_path = file.read().rstrip()
        asset_path = os.path.join(report_path, filename)
        if os.path.exists(asset_path):
            return send_file(asset_path)
        else:
            return make_response('Asset not found', 404)
    except Exception as e:
        return make_response('Asset not found', 404)

@app.route("/cancel_job", methods=['POST'])
def cancel_job():
    """Cancel a SLURM job"""
    try:
        job_id = request.json.get('job_id')
        if not job_id:
            return jsonify({'status': 'error', 'message': 'Job ID is required'}), 400
        
        # Execute scancel command
        result = subprocess.run(['scancel', str(job_id)], 
                              capture_output=True, text=True, timeout=10)
        
        if result.returncode == 0:
            return jsonify({'status': 'success', 'message': f'Job {job_id} cancelled successfully'})
        else:
            return jsonify({'status': 'error', 'message': f'Failed to cancel job {job_id}: {result.stderr.strip()}'}), 500
            
    except subprocess.TimeoutExpired:
        return jsonify({'status': 'error', 'message': 'Cancel operation timed out'}), 500
    except Exception as e:
        return jsonify({'status': 'error', 'message': f'Error cancelling job: {str(e)}'}), 500

def get_slurm_status():
    """Get SLURM queue status as structured data for table display"""
    try:
        # Get current user
        current_user = os.environ.get('USER', 'unknown')
        
        # Get squeue output with specific format
        result = subprocess.check_output(['squeue', '--format=%i %.18j %.8u %.8T %.10M %.9l %.6D %R', '--noheader'], 
                                       stderr=subprocess.DEVNULL).decode()
        
        jobs = []
        for line in result.strip().split('\n'):
            if line.strip() and 'sim' not in line.lower():  # Skip simulation jobs and empty lines
                parts = line.split()
                if len(parts) >= 8:
                    job = {
                        'job_id': parts[0],
                        'name': parts[1],
                        'user': parts[2], 
                        'state': parts[3],
                        'time': parts[4],
                        'time_limit': parts[5],
                        'nodes': parts[6],
                        'nodelist': ' '.join(parts[7:]),  # Join remaining parts for nodelist
                        'is_current_user': parts[2] == current_user[:len(parts[2])] # Check if job belongs to current user
                    }
                    jobs.append(job)
        
        return jobs
    except (subprocess.CalledProcessError, FileNotFoundError):
        # Return empty list if squeue command fails
        return []

def check_queue_running_jobs(queue_name):
    """Check if there are running jobs in a specific SLURM queue"""
    try:
        # Use squeue to check for running jobs in the specific partition
        squeue_output = subprocess.check_output(['squeue', '-p', queue_name, '-t', 'RUNNING'], 
                                               stderr=subprocess.DEVNULL).decode()
        # If there's output beyond the header line, there are running jobs
        lines = squeue_output.strip().split('\n')
        return len(lines) > 1  # More than just the header line means there are running jobs
    except (subprocess.CalledProcessError, FileNotFoundError):
        return False  # If command fails, assume no running jobs

def get_slurm_output(slurm_output_path = home_path+"/work/logs/slurm_output.txt"):
    with open(slurm_output_path, 'r') as file:  # r to open file in READ mode
        log_content = file.read()
    return log_content.replace('\n','<br>')

def parse_slurm_log_for_errors(slurm_output_path = home_path+"/work/logs/slurm_output.txt"):
    """
    Parse SLURM log file to extract error information from the last entries
    Returns a tuple (has_error, error_message)
    """
    try:
        with open(slurm_output_path, 'r') as file:
            log_content = file.read().strip()
        
        if not log_content:
            return False, "No log content available"
        
        # Split into lines and get the last few entries
        lines = log_content.split('\n')
        last_lines = lines[-10:]  # Check last 10 lines for errors
        
        # Common error patterns in SLURM logs
        error_patterns = [
            r'error',
            r'failed',
            r'exception',
            r'traceback',
            r'stderr',
            r'cannot',
            r'unable',
            r'permission denied',
            r'no such file',
            r'command not found',
            r'killed',
            r'timeout',
            r'cancelled'
        ]
        
        error_messages = []
        
        # Check for error patterns in the last lines
        for line in reversed(last_lines):  # Check from newest to oldest
            line_lower = line.lower().strip()
            if any(pattern in line_lower for pattern in error_patterns):
                # Clean up the error message
                clean_line = line.strip()
                if clean_line and len(clean_line) > 10:  # Avoid very short meaningless lines
                    error_messages.append(clean_line)
                    if len(error_messages) >= 3:  # Limit to 3 error lines
                        break
        
        if error_messages:
            # Return the most recent meaningful error
            return True, error_messages[0]
        else:
            # Check if the log ends with any completion indicators
            last_line = lines[-1].lower().strip() if lines else ""
            if any(word in last_line for word in ['completed', 'finished', 'done', 'success']):
                return False, "Job completed but report generation may have failed"
            else:
                return False, "No report available for quick view. Check SLURM logs for details."
                
    except (IOError, OSError):
        return True, "Unable to read SLURM log file"
    except Exception as e:
        return True, f"Error parsing log: {str(e)}"

def report_viewer(report_path):
    with open(report_path+"index.html", 'r') as file:  # r to open file in READ mode
            report_viewer_content = file.read()
    
    # Extract the head section to get CSS and JS dependencies
    head_content = ""
    if '<head>' in report_viewer_content and '</head>' in report_viewer_content:
        head_content = report_viewer_content.split('<head>')[1].split('</head>')[0]
    
    # Extract main content
    report_viewer_body = report_viewer_content
    if '<body>' in report_viewer_content and '</body>' in report_viewer_content:
        report_viewer_body = report_viewer_content.split('<body>')[1].split('</body>')[0]
        
        # Remove header if present
        if '<header' in report_viewer_body and '</header>' in report_viewer_body:
            report_viewer_body = report_viewer_body.split('</header>')[1]
    
    # Fix relative asset paths - convert them to use our report_assets route
    import re
    
    # Remove the original report's sidebar menu if it exists (should be redundant now but safe to keep)
    report_viewer_body = re.sub(r'<nav id="sidebarMenu".*?</nav>', '', report_viewer_body, flags=re.DOTALL)

    # Fix CSS links
    head_content = re.sub(r'''href=(['"])(?!/|http|https|data:)([^'"]+\.css[^'"]*)['"]''', r'href="/report_assets/\2"', head_content)
    
    # Fix JS script sources
    head_content = re.sub(r'''src=(['"])(?!/|http|https|data:)([^'"]+\.js[^'"]*)['"]''', r'src="/report_assets/\2"', head_content)
    report_viewer_body = re.sub(r'''src=(['"])(?!/|http|https|data:)([^'"]+\.js[^'"]*)['"]''', r'src="/report_assets/\2"', report_viewer_body)
    
    # Fix image sources
    report_viewer_body = re.sub(r'''src=(['"])(?!/|http|https|data:)([^'"]+\.(?:png|jpg|jpeg|gif|svg)[^'"]*)['"]''', r'src="/report_assets/\2"', report_viewer_body)
    
    # Fix any other asset references (like data files for plots)
    report_viewer_body = re.sub(r'''(['"])(?!/|http|https|data:)([^'"]+\.(?:json|csv|data|yml|yaml)[^'"]*)['"]''', r'"/report_assets/\2"', report_viewer_body)

    # Prepare the report path for the file browser link (remove root prefix and ensure it starts with /)
    report_path_for_link = report_path.replace(root, "").lstrip("/")

    # Insert body into html template
    report_viewer_template = render_template('latest_report.html')
    report_viewer_template = report_viewer_template.replace("QQREPORT_BODY", report_viewer_body)
    report_viewer_template = report_viewer_template.replace("QQREPORT_MENU", "")
    report_viewer_template = report_viewer_template.replace("QQREPORT_PATH", report_path_for_link)
    report_viewer_template = report_viewer_template.replace("QQREPORT_HEAD", head_content)

    res = make_response(report_viewer_template, 200)
    return res
   

class PathView(MethodView):
    """
    File browser functionality based on flask-file-server by Wildog
    https://github.com/Wildog/flask-file-server
    
    Enhanced with quantum computing dashboard integration
    """
    def get(self, p=''):
        hide_dotfile = request.args.get('hide-dotfile', request.cookies.get('hide-dotfile', 'no'))

        path = os.path.join(root, p)

        if os.path.isdir(path):
            contents = []
            total = {'size': 0, 'dir': 0, 'file': 0}

            for filename in os.listdir(path):
                if filename in ignored:
                    continue
                if hide_dotfile == 'yes' and filename[0] == '.':
                    continue
                filepath = os.path.join(path, filename)
                stat_res = os.stat(filepath)
                info = {}
                info['name'] = filename
                info['mtime'] = stat_res.st_mtime
                ft = get_type(stat_res.st_mode)
                info['type'] = ft
                total[ft] += 1
                sz = stat_res.st_size
                info['size'] = sz
                total['size'] += sz
                contents.append(info)
          
            page = render_template('file_browser.html', path=p, contents=contents, total=total, hide_dotfile=hide_dotfile)
            res = make_response(page, 200)
            res.set_cookie('hide-dotfile', hide_dotfile, max_age=16070400)

        elif os.path.isfile(path):
            if 'Range' in request.headers:
                start, end = get_range(request)
                res = partial_response(path, start, end)
            else:
                filename, file_extension = os.path.splitext(path)
                if file_extension in ['.html', '.yml','.json']:
                    with open(path, 'r') as file:  # r to open file in READ mode
                        report_viewer_content = file.read()
                    res = make_response(report_viewer_content, 200)
                else:
                    res = send_file(path)
                    #res.headers.add('Content-Disposition', 'attachment')
        else:
            res = make_response('Not found', 404)
        return res
    
    def put(self, p=''):
        if request.cookies.get('auth_cookie') == key:
            path = os.path.join(root, p)
            dir_path = os.path.dirname(path)
            Path(dir_path).mkdir(parents=True, exist_ok=True)

            info = {}
            if os.path.isdir(dir_path):
                try:
                    filename = secure_filename(os.path.basename(path))
                    with open(os.path.join(dir_path, filename), 'wb') as f:
                        f.write(request.stream.read())
                except Exception as e:
                    info['status'] = 'error'
                    info['msg'] = str(e)
                else:
                    info['status'] = 'success'
                    info['msg'] = 'File Saved'
            else:
                info['status'] = 'error'
                info['msg'] = 'Invalid Operation'
            res = make_response(json.JSONEncoder().encode(info), 201)
            res.headers.add('Content-type', 'application/json')
        else:
            info = {} 
            info['status'] = 'error'
            info['msg'] = 'Authentication failed'
            res = make_response(json.JSONEncoder().encode(info), 401)
            res.headers.add('Content-type', 'application/json')
        return res

    def post(self, p=''):
        if request.cookies.get('auth_cookie') == key:
            path = os.path.join(root, p)
            Path(path).mkdir(parents=True, exist_ok=True)
    
            info = {}
            if os.path.isdir(path):
                files = request.files.getlist('files[]')
                for file in files:
                    filename = secure_filename(file.filename)
                    file.save(os.path.join(path, filename))
                info['status'] = 'success'
                info['msg'] = 'Files Saved'
            else:
                info['status'] = 'error'
                info['msg'] = 'Invalid Operation'
        else:
            info = {} 
            info['status'] = 'error'
            info['msg'] = 'Authentication failed'
            res = make_response(json.JSONEncoder().encode(info), 200)
            res.headers.add('Content-type', 'application/json')
        return res    
    
    def delete(self, p=''):
        if request.cookies.get('auth_cookie') == key:
            path = os.path.join(root, p)
            dir_path = os.path.dirname(path)
            Path(dir_path).mkdir(parents=True, exist_ok=True)

            info = {}
            if os.path.isdir(dir_path):
                try:
                    filename = secure_filename(os.path.basename(path))
                    os.remove(os.path.join(dir_path, filename))
                    os.rmdir(dir_path)
                except Exception as e:
                    info['status'] = 'error'
                    info['msg'] = str(e)
                else:
                    info['status'] = 'success'
                    info['msg'] = 'File Deleted'
            else:
                info['status'] = 'error'
                info['msg'] = 'Invalid Operation'
            res = make_response(json.JSONEncoder().encode(info), 204)
            res.headers.add('Content-type', 'application/json')
        else:
            info = {}
            info['status'] = 'error'
            info['msg'] = 'Authentication failed'
            res = make_response(json.JSONEncoder().encode(info), 401)
            res.headers.add('Content-type', 'application/json')
        return res

def generate_topology_visualization(connectivity_data, topology_type):
    """
    Generate a topology visualization using rustworkx mpl_draw function.
    
    Args:
        connectivity_data: List of qubit pairs representing connections
        topology_type: String indicating the topology type
        
    Returns:
        str: Base64 encoded PNG image of the topology, or None if generation fails
    """
    
    if not connectivity_data or not HAS_RUSTWORKX or not HAS_MATPLOTLIB:
        return None
    
    try:
        # Create a graph using rustworkx
        graph = rx.PyGraph()
        
        # Find all unique qubits from connectivity data
        qubits = set()
        for connection in connectivity_data:
            if len(connection) >= 2:
                qubits.add(connection[0])
                qubits.add(connection[1])
        
        if len(qubits) == 0:
            return None
        
        # Add nodes to graph
        qubit_to_node = {}
        node_labels = {}
        for qubit in sorted(qubits):
            node_idx = graph.add_node(f"Q{qubit}")
            qubit_to_node[qubit] = node_idx
            node_labels[node_idx] = f"Q{qubit}"
        
        # Add edges
        edge_list = []
        for connection in connectivity_data:
            if len(connection) >= 2:
                qubit1, qubit2 = connection[0], connection[1]
                if qubit1 in qubit_to_node and qubit2 in qubit_to_node:
                    graph.add_edge(qubit_to_node[qubit1], qubit_to_node[qubit2], None)
                    edge_list.append((qubit1, qubit2))
        
        # Generate layout based on topology type
        if topology_type == 'chain':
            # Linear layout for chains
            pos = {}
            sorted_nodes = sorted(qubits)
            for i, qubit in enumerate(sorted_nodes):
                node_idx = qubit_to_node[qubit]
                pos[node_idx] = (i * 2, 0)
        elif topology_type == 'ring':
            # Circular layout for rings
            pos = rx.circular_layout(graph)
        elif topology_type == 'lattice':
            # Grid layout for lattices
            pos = rx.spring_layout(graph, k=2.0, num_iter=100)
        elif topology_type == 'star':
            # Star layout - center node in middle, others around
            degrees = [graph.degree(node) for node in graph.node_indices()]
            center_node = degrees.index(max(degrees))
            pos = {}
            pos[center_node] = (0, 0)
            other_nodes = [i for i in range(len(qubits)) if i != center_node]
            for i, node in enumerate(other_nodes):
                angle = 2 * np.pi * i / len(other_nodes)
                pos[node] = (2 * np.cos(angle), 2 * np.sin(angle))
        else:
            # Default spring layout for other topologies
            pos = rx.spring_layout(graph, k=2.0, num_iter=100)

        # Create figure and use mpl_draw
        fig, ax = plt.subplots(figsize=(10, 8))
        ax.set_title(f'Quantum Device Topology: {topology_type.title()}', fontsize=16, fontweight='bold')
        
        # Use rustworkx mpl_draw for graph visualization
        try:
            
            # Use mpl_draw with minimal parameters first
            mpl_draw(
                graph,
                pos=pos,
                ax=ax
            )
            
            # Add labels manually if mpl_draw doesn't support them
            for node_idx, (x, y) in pos.items():
                if node_idx in node_labels:
                    ax.text(x, y, node_labels[node_idx], ha='center', va='center', 
                           fontsize=12, fontweight='bold', 
                           bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8))
        except Exception as draw_error:
            print(f"DEBUG: Error with mpl_draw: {draw_error}")
            # Fallback to manual plotting if mpl_draw fails
            
            # Plot edges manually
            for qubit1, qubit2 in edge_list:
                node1_idx = qubit_to_node[qubit1]
                node2_idx = qubit_to_node[qubit2]
                if node1_idx in pos and node2_idx in pos:
                    x1, y1 = pos[node1_idx]
                    x2, y2 = pos[node2_idx]
                    ax.plot([x1, x2], [y1, y2], 'b-', linewidth=2, alpha=0.7)
            
            # Plot nodes manually
            x_coords = []
            y_coords = []
            labels = []
            for qubit in sorted(qubits):
                node_idx = qubit_to_node[qubit]
                if node_idx in pos:
                    x_coords.append(pos[node_idx][0])
                    y_coords.append(pos[node_idx][1])
                    labels.append(f"Q{qubit}")
            
            ax.scatter(x_coords, y_coords, c='lightblue', s=800, alpha=0.8, 
                      edgecolors='navy', linewidths=2)
            
            # Add labels manually
            for i, label in enumerate(labels):
                ax.annotate(label, (x_coords[i], y_coords[i]), 
                           ha='center', va='center', fontweight='bold', fontsize=12)
            
            print("DEBUG: Used manual plotting fallback")
        
        # Styling
        ax.axis('equal')
        ax.axis('off')
        plt.tight_layout()
        
        # Add some information text
        info_text = f"Topology: {topology_type.title()}\nQubits: {len(qubits)}\nConnections: {len(edge_list)}"
        plt.figtext(0.02, 0.02, info_text, fontsize=10, 
                   bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgray", alpha=0.8))
        
        # Convert plot to base64 string
        img_buffer = io.BytesIO()
        plt.savefig(img_buffer, format='png', dpi=150, bbox_inches='tight', 
                   facecolor='white', edgecolor='none')
        img_buffer.seek(0)
        img_base64 = base64.b64encode(img_buffer.getvalue()).decode()
        plt.close()
        
        print("DEBUG: Successfully generated base64 image")
        return img_base64
        
    except Exception as e:
        print(f"DEBUG: Error generating topology visualization: {e}")
        import traceback
        traceback.print_exc()
        return None

def get_connectivity_data_from_qpu_config(qpu_path):
    """
    Extract connectivity data from QPU configuration files.
    
    Args:
        qpu_path: Path to the QPU directory
        
    Returns:
        list: List of connectivity pairs, or None if not found
    """
    import yaml
    import json

    # Look for common configuration file names
    config_files = ['parameters.json', 'topology.json']
    
    for config_file in config_files:
        config_path = os.path.join(qpu_path, config_file)
        if os.path.exists(config_path):
            try:
                # Try to read the configuration file (json or yaml)
                if config_file.endswith('.json'):
                    with open(config_path, 'r') as f:
                        config_data = json.load(f)
                elif config_file.endswith('.yaml') or config_file.endswith('.yml'):
                    with open(config_path, 'r') as f:
                        config_data = yaml.load(f, Loader=yaml.FullLoader)
                else:
                    continue  # Skip unsupported file types
                
                # Look for connectivity data
                connectivity = None
                connectivity_keys = [
                    'topology', 'connectivity', 'connections', 'coupling_map', 'couplings',
                    'native_gates', 'edges', 
                ]
                
                # Search through the config structure
                for key in connectivity_keys:
                    if key in config_data:
                        connectivity = config_data[key]
                        break
                
                # Also check nested structures
                if not connectivity:
                    for section in ['platform', 'device', 'chip', 'qubits']:
                        if section in config_data:
                            section_data = config_data[section]
                            for key in connectivity_keys:
                                if key in section_data:
                                    connectivity = section_data[key]
                                    break
                            if connectivity:
                                break
                
                # If we found connectivity data, format it
                if connectivity:
                    if isinstance(connectivity, list):
                        return connectivity
                    elif isinstance(connectivity, dict):
                        pairs = []
                        for source, targets in connectivity.items():
                            if isinstance(targets, list):
                                for target in targets:
                                    pairs.append([int(source), int(target)])
                            else:
                                pairs.append([int(source), int(targets)])
                        return pairs
                
            except Exception as e:
                print(f"Error reading config file {config_path}: {e}")
                continue
    
    return None

def infer_topology_from_connectivity(connectivity_data):
    """
    Infer topology type from connectivity data using rustworkx graph analysis.
    
    Args:
        connectivity_data: List of qubit pairs representing connections, e.g. [[0,1], [1,2], [2,3]]
        
    Returns:
        str: Topology type ('chain', 'lattice', 'bow_tie', 'honeycomb', 'star', 'ring', 'custom')
    """
    if not connectivity_data or not HAS_RUSTWORKX:
        return 'unknown'
    
    try:
        # Create a graph using rustworkx
        graph = rx.PyGraph()
        
        # Find all unique qubits from connectivity data
        qubits = set()
        for connection in connectivity_data:
            if len(connection) >= 2:
                qubits.add(connection[0])
                qubits.add(connection[1])
        
        if len(qubits) == 0:
            return 'isolated'
        
        # Add nodes to graph
        qubit_to_node = {}
        for qubit in sorted(qubits):
            node_idx = graph.add_node(qubit)
            qubit_to_node[qubit] = node_idx
        
        # Add edges
        for connection in connectivity_data:
            if len(connection) >= 2:
                qubit1, qubit2 = connection[0], connection[1]
                if qubit1 in qubit_to_node and qubit2 in qubit_to_node:
                    graph.add_edge(qubit_to_node[qubit1], qubit_to_node[qubit2], None)
        
        num_nodes = len(qubits)
        num_edges = len(connectivity_data)
        
        # Single qubit case
        if num_nodes == 1:
            return 'single'
        
        # Calculate graph metrics
        degrees = [graph.degree(node) for node in graph.node_indices()]
        max_degree = max(degrees) if degrees else 0
        min_degree = min(degrees) if degrees else 0
        avg_degree = sum(degrees) / len(degrees) if degrees else 0
        
        # Check if graph is connected
        is_connected = rx.is_connected(graph)
        
        # Topology classification logic
        
        # Chain topology: linear arrangement, max degree 2, exactly n-1 edges
        if (max_degree <= 2 and num_edges == num_nodes - 1 and is_connected and
            degrees.count(1) == 2 and degrees.count(2) == num_nodes - 2):
            return 'chain'
        
        # Ring topology: circular arrangement, all degree 2, exactly n edges
        if (max_degree == 2 and min_degree == 2 and num_edges == num_nodes and is_connected):
            return 'ring'
        
        # Star topology: one central node connected to all others
        if (max_degree == num_nodes - 1 and degrees.count(1) == num_nodes - 1 and 
            degrees.count(num_nodes - 1) == 1):
            return 'star'
        
        # Lattice topology: regular 2D grid-like structure
        # Typical characteristics: nodes have degree 2-4, rectangular arrangement
        if (2 <= avg_degree <= 4 and max_degree <= 4 and is_connected):
            # Check for regular lattice patterns
            corner_nodes = degrees.count(2)  # Corner nodes in 2D lattice
            edge_nodes = degrees.count(3)    # Edge nodes in 2D lattice  
            inner_nodes = degrees.count(4)   # Inner nodes in 2D lattice
            
            total_special = corner_nodes + edge_nodes + inner_nodes
            if total_special == num_nodes and corner_nodes >= 4:
                return 'lattice'
        
        # Bow tie topology: two connected components joined at a bridge
        if num_nodes >= 5:
            # Look for articulation points (bridge nodes)
            articulation_points = rx.articulation_points(graph)
            if len(articulation_points) == 1:
                # Remove the articulation point and check connected components
                temp_graph = graph.copy()
                temp_graph.remove_node(articulation_points[0])
                components = rx.connected_components(temp_graph)
                if len(components) == 2:
                    comp_sizes = [len(comp) for comp in components]
                    # Bow tie typically has roughly equal-sized components
                    if abs(comp_sizes[0] - comp_sizes[1]) <= 1:
                        return 'bow_tie'
        
        # Honeycomb topology: hexagonal lattice structure
        # Characteristics: degree 3 for most nodes, specific pattern
        if (min_degree >= 2 and max_degree <= 3 and is_connected):
            degree_3_nodes = degrees.count(3)
            if degree_3_nodes >= num_nodes * 0.8:  # Most nodes have degree 3
                # Check for hexagonal cycles (harder to detect, simplified check)
                return 'honeycomb'
        
        # If none of the above patterns match
        return 'custom'
        
    except Exception as e:
        print(f"Error analyzing topology: {e}")
        return 'unknown'
    """
    Infer topology type from connectivity data using rustworkx graph analysis.
    
    Args:
        connectivity_data: List of qubit pairs representing connections, e.g. [[0,1], [1,2], [2,3]]
        
    Returns:
        str: Topology type ('chain', 'lattice', 'bow_tie', 'honeycomb', 'star', 'ring', 'custom')
    """
    if not connectivity_data or not HAS_RUSTWORKX:
        return 'unknown'
    
    try:
        # Create a graph using rustworkx
        graph = rx.PyGraph()
        
        # Find all unique qubits from connectivity data
        qubits = set()
        for connection in connectivity_data:
            if len(connection) >= 2:
                qubits.add(connection[0])
                qubits.add(connection[1])
        
        if len(qubits) == 0:
            return 'isolated'
        
        # Add nodes to graph
        qubit_to_node = {}
        for qubit in sorted(qubits):
            node_idx = graph.add_node(qubit)
            qubit_to_node[qubit] = node_idx
        
        # Add edges
        for connection in connectivity_data:
            if len(connection) >= 2:
                qubit1, qubit2 = connection[0], connection[1]
                if qubit1 in qubit_to_node and qubit2 in qubit_to_node:
                    graph.add_edge(qubit_to_node[qubit1], qubit_to_node[qubit2], None)
        
        num_nodes = len(qubits)
        num_edges = len(connectivity_data)
        
        # Single qubit case
        if num_nodes == 1:
            return 'single'
        
        # Calculate graph metrics
        degrees = [graph.degree(node) for node in graph.node_indices()]
        max_degree = max(degrees) if degrees else 0
        min_degree = min(degrees) if degrees else 0
        avg_degree = sum(degrees) / len(degrees) if degrees else 0
        
        # Check if graph is connected
        is_connected = rx.is_connected(graph)
        
        # Topology classification logic
        
        # Chain topology: linear arrangement, max degree 2, exactly n-1 edges
        if (max_degree <= 2 and num_edges == num_nodes - 1 and is_connected and
            degrees.count(1) == 2 and degrees.count(2) == num_nodes - 2):
            return 'chain'
        
        # Ring topology: circular arrangement, all degree 2, exactly n edges
        if (max_degree == 2 and min_degree == 2 and num_edges == num_nodes and is_connected):
            return 'ring'
        
        # Star topology: one central node connected to all others
        if (max_degree == num_nodes - 1 and degrees.count(1) == num_nodes - 1 and 
            degrees.count(num_nodes - 1) == 1):
            return 'star'
        
        # Lattice topology: regular 2D grid-like structure
        # Typical characteristics: nodes have degree 2-4, rectangular arrangement
        if (2 <= avg_degree <= 4 and max_degree <= 4 and is_connected):
            # Check for regular lattice patterns
            corner_nodes = degrees.count(2)  # Corner nodes in 2D lattice
            edge_nodes = degrees.count(3)    # Edge nodes in 2D lattice  
            inner_nodes = degrees.count(4)   # Inner nodes in 2D lattice
            
            total_special = corner_nodes + edge_nodes + inner_nodes
            if total_special == num_nodes and corner_nodes >= 4:
                return 'lattice'
        
        # Bow tie topology: two connected components joined at a bridge
        if num_nodes >= 5:
            # Look for articulation points (bridge nodes)
            articulation_points = rx.articulation_points(graph)
            if len(articulation_points) == 1:
                # Remove the articulation point and check connected components
                temp_graph = graph.copy()
                temp_graph.remove_node(articulation_points[0])
                components = rx.connected_components(temp_graph)
                if len(components) == 2:
                    comp_sizes = [len(comp) for comp in components]
                    # Bow tie typically has roughly equal-sized components
                    if abs(comp_sizes[0] - comp_sizes[1]) <= 1:
                        return 'bow_tie'
        
        # Honeycomb topology: hexagonal lattice structure
        # Characteristics: degree 3 for most nodes, specific pattern
        if (min_degree >= 2 and max_degree <= 3 and is_connected):
            degree_3_nodes = degrees.count(3)
            if degree_3_nodes >= num_nodes * 0.8:  # Most nodes have degree 3
                # Check for hexagonal cycles (harder to detect, simplified check)
                return 'honeycomb'
        
        # If none of the above patterns match
        return 'custom'
        
    except Exception as e:
        print(f"Error analyzing topology: {e}")
        return 'unknown'

def get_topology_from_qpu_config(qpu_path):
    """
    Extract topology information from QPU configuration files.
    
    Args:
        qpu_path: Path to the QPU directory
        
    Returns:
        str: Inferred topology type
    """
    import yaml
    import json

    # Look for common configuration file names
    config_files = ['parameters.json', 'topology.json']
    
    for config_file in config_files:
        config_path = os.path.join(qpu_path, config_file)
        print(f"Checking for connectivity in {config_path}")
        if os.path.exists(config_path):
            try:
                # Try to read the configuration file (json or yaml)
                if config_file.endswith('.json'):
                    with open(config_path, 'r') as f:
                        config_data = json.load(f)
                elif config_file.endswith('.yaml') or config_file.endswith('.yml'):
                    with open(config_path, 'r') as f:
                        config_data = yaml.load(f, Loader=yaml.FullLoader)
                else:
                    continue  # Skip unsupported file types
            except Exception as e:
                print(f"Error reading config file {config_path}: {e}")  

                continue

            try:
                # Look for connectivity data in various possible locations
                connectivity = None
                
                # Common key names for connectivity data
                connectivity_keys = [
                    'topology', 'connectivity', 'connections', 'coupling_map', 'couplings',
                    'native_gates', 'edges', 
                ]
                
                # Search through the config structure
                for key in connectivity_keys:
                    if key in config_data:
                        print(f"Found connectivity key: {key}")
                        connectivity = config_data[key]
                        break
                
                # Also check nested structures
                if not connectivity:
                    for section in ['platform', 'device', 'chip', 'qubits']:
                        if section in config_data:
                            section_data = config_data[section]
                            for key in connectivity_keys:
                                if key in section_data:
                                    connectivity = section_data[key]
                                    break
                            if connectivity:
                                break
                
                # If we found connectivity data, analyze it
                if connectivity:
                    # Handle different formats of connectivity data
                    if isinstance(connectivity, list):
                        # Direct list of connections
                        return infer_topology_from_connectivity(connectivity)
                    elif isinstance(connectivity, dict):
                        # Dictionary format - extract pairs
                        pairs = []
                        for source, targets in connectivity.items():
                            if isinstance(targets, list):
                                for target in targets:
                                    pairs.append([int(source), int(target)])
                            else:
                                pairs.append([int(source), int(targets)])
                        return infer_topology_from_connectivity(pairs)
                
            except (yaml.YAMLError, IOError, ValueError) as e:
                print(f"Error reading config file {config_path}: {e}")
                continue
    
    return 'N/A'

"""Read YAML File"""
import yaml
def read_yaml_file(file_path):
    with open(file_path, 'r') as file:
        data = yaml.load(file, Loader=yaml.FullLoader)
    return data

"""Write YAML File"""
def write_yaml_file(file_path, data):
    with open(file_path, 'w') as file:
        yaml.dump(data, file)

"""Read JSON File"""
def read_json_file(file_path):
    with open(file_path, 'r') as file:
        data = json.load(file)
    return data

"""Write JSON File"""
def write_json_file(file_path, data):
    with open(file_path, 'w') as file:
        json.dump(data, file)

"""Format YAML as hhtp response"""
def yaml_response(data):
    response = make_response(yaml.dump(data), 200)
    response.headers.add('Content-type', 'application/x-yaml')
    return response

"""Format JSON as hhtp response"""
def json_response(data):    
    response = make_response(json.dumps(data), 200)
    response.headers.add('Content-type', 'application/json')
    return response


"""Format HTML as hhtp response"""
path_view = PathView.as_view('path_view')
app.add_url_rule('/files', view_func=path_view)
app.add_url_rule('/files/<path:p>', view_func=path_view)


@app.route("/qpus")
def qpus():
    qrc_path = os.environ.get('QIBOLAB_PLATFORMS', os.path.join(root, 'qibolab_platforms_qrc'))
    qpus_list = []
    
    # Get git branch information
    git_branch = 'N/A'
    git_commit = 'N/A'
    
    if os.path.exists(qrc_path):
        try:
            # Check if the directory is a git repository
            git_dir = os.path.join(qrc_path, '.git')
            if os.path.exists(git_dir) or os.path.exists(os.path.join(os.path.dirname(qrc_path), '.git')):
                # Get current branch
                branch_output = subprocess.check_output(['git', 'branch', '--show-current'], 
                                                      cwd=qrc_path, stderr=subprocess.DEVNULL).decode().strip()
                if branch_output:
                    git_branch = branch_output
                
                # Get short commit hash
                commit_output = subprocess.check_output(['git', 'rev-parse', '--short', 'HEAD'], 
                                                      cwd=qrc_path, stderr=subprocess.DEVNULL).decode().strip()
                if commit_output:
                    git_commit = commit_output
        except (subprocess.CalledProcessError, FileNotFoundError, OSError):
            pass # Keep defaults if git commands fail
    
    try:
        with open(os.path.join(qrc_path, 'queues.json'), 'r') as f:
            queues = json.load(f)
    except (IOError, json.JSONDecodeError):
        queues = {}

    if os.path.exists(qrc_path):
        for qpu_name in os.listdir(qrc_path):
            qpu_path = os.path.join(qrc_path, qpu_name)
            if os.path.isdir(qpu_path) and not qpu_name.startswith('.'):
                # Defaults
                num_qubits = 'N/A'
                topology = 'N/A'
                calibration_time = 'N/A'
                status = 'offline'
                
                # Get queue info and check status
                queue_name = queues.get(qpu_name, 'N/A')
                if queue_name != 'N/A':
                    try:
                        sinfo_output = subprocess.check_output(['sinfo', '-p', queue_name]).decode()
                        if queue_name in sinfo_output:
                            # Check if there are running jobs in this queue
                            if check_queue_running_jobs(queue_name):
                                status = 'running'
                            else:
                                status = 'online'
                    except (subprocess.CalledProcessError, FileNotFoundError):
                        pass # Keep status as offline if sinfo fails or queue not found

                # Get qubit count from platform.py
                platform_py_path = os.path.join(qpu_path, 'platform.py')
                if os.path.exists(platform_py_path):
                    with open(platform_py_path, 'r') as f:
                        for line in f:
                            if 'NUM_QUBITS' in line:
                                try:
                                    num_qubits = int(line.split('=')[1].strip())
                                    break
                                except (ValueError, IndexError):
                                    pass
                
                # Infer topology from configuration files
                topology = get_topology_from_qpu_config(qpu_path)
                
                qpus_list.append({
                    'name': qpu_name,
                    'qubits': num_qubits,
                    'status': status,
                    'queue': queue_name,
                    'topology': topology,
                    'calibration_time': calibration_time
                })

    return render_template('qpus.html', qpus=qpus_list, git_branch=git_branch, git_commit=git_commit, platforms_path=qrc_path)

@app.route("/experiments")
def experiments():
    """
    Experiment builder page.
    
    - Fetches available qibocal protocols dynamically from qibocal.protocols module.
    - Fetches available QPUs from the platforms directory.
    - Renders the experiment builder interface.
    """
    protocols = get_qibocal_protocols()
    qpus = get_available_qpu_list()
    
    return render_template('experiments.html', protocols=protocols, qpus=qpus)

def get_qibocal_protocols():
    """
    Dynamically discover all available qibocal protocols by finding Routine objects.
    Returns a dictionary categorized by protocol type.
    """
    try:
        import qibocal.protocols as protocols_module
        import qibocal.auto.operation
        import inspect
        import importlib
        import signal
        
        # Temporarily disable signal handling to avoid "signal only works in main thread" error
        old_signal = signal.signal
        signal.signal = lambda sig, handler: None
        
        routine_protocols = []
        
        try:
            # First, get all DIRECT Routine objects from the protocols module
            for name, obj in inspect.getmembers(protocols_module):
                if (not name.startswith('_') and name != 'Enum' and
                    hasattr(obj, '__class__') and
                    str(obj.__class__) == "<class 'qibocal.auto.operation.Routine'>"):
                    
                    routine_protocols.append({
                        'id': name.lower(),
                        'name': name.replace('_', ' ').title(),
                        'class_name': name,
                        'module_name': 'protocols',  # These are direct imports
                        'module_path': f'qibocal.protocols.{name}',
                        'routine_obj': obj
                    })
            
            # Then, get all protocol modules and their Routine objects (like rabi submodule)
            for name, obj in inspect.getmembers(protocols_module):
                if not name.startswith('_') and name != 'Enum':
                    try:
                        # Check if it's a module (has __path__ or __file__)
                        if hasattr(obj, '__path__') or (hasattr(obj, '__file__') and obj.__file__):
                            module_path = f'qibocal.protocols.{name}'
                            
                            # Try to import the module and look for Routine objects
                            try:
                                imported_module = importlib.import_module(module_path)
                                
                                # Look for Routine objects in the module
                                for attr_name, attr_obj in inspect.getmembers(imported_module):
                                    if (not attr_name.startswith('_') and 
                                        hasattr(attr_obj, '__class__') and
                                        str(attr_obj.__class__) == "<class 'qibocal.auto.operation.Routine'>"):
                                        
                                        # Only add if we haven't already found this routine directly
                                        if not any(p['class_name'] == attr_name for p in routine_protocols):
                                            routine_protocols.append({
                                                'id': attr_name.lower(),
                                                'name': attr_name.replace('_', ' ').title(),
                                                'class_name': attr_name,
                                                'module_name': name,
                                                'module_path': module_path,
                                                'routine_obj': attr_obj
                                            })
                                        
                            except Exception as import_error:
                                # If we can't import the module, skip it but don't fail completely
                                print(f"Warning: Could not import {module_path}: {import_error}")
                                continue
                                
                    except Exception:
                        # Skip attributes that can't be accessed
                        continue
                        
        finally:
            # Restore signal handling
            signal.signal = old_signal
        
        # Remove duplicates based on class name (just in case)
        seen = set()
        unique_protocols = []
        for protocol in routine_protocols:
            key = protocol['class_name']
            if key not in seen:
                seen.add(key)
                unique_protocols.append(protocol)
        
        # Try to categorize protocols based on their name patterns
        categorized = {
            "Characterization": [],
            "Calibration": [],
            "Verification": [],
            "Coherence": [],
            "Spectroscopy": [],
            "Readout": [],
            "Two-Qubit": [],
            "Couplers": [],
            "Other": []
        }
        
        for protocol in unique_protocols:
            name_lower = protocol['name'].lower()
            module_name = protocol['module_name'].lower()
            class_name = protocol['class_name'].lower()
            
            # Categorize based on protocol name patterns
            if any(keyword in class_name or keyword in module_name 
                   for keyword in ['spectroscopy', 'resonator_spectroscopy', 'qubit_spectroscopy']):
                categorized["Spectroscopy"].append(protocol)
            elif any(keyword in class_name or keyword in module_name 
                     for keyword in ['readout', 'classification', 'single_shot', 'state_discrimination']):
                categorized["Readout"].append(protocol)
            elif any(keyword in class_name or keyword in module_name 
                     for keyword in ['coherence', 't1', 't2', 'spin_echo', 'ramsey']):
                categorized["Coherence"].append(protocol)
            elif any(keyword in class_name or keyword in module_name 
                     for keyword in ['coupler', 'avoided_crossing']):
                categorized["Couplers"].append(protocol)
            elif any(keyword in class_name or keyword in module_name 
                     for keyword in ['cross_resonance', 'chevron', 'two_qubit', 'chsh', 'mermin', 'tomography']):
                categorized["Two-Qubit"].append(protocol)
            elif any(keyword in class_name or keyword in module_name 
                     for keyword in ['rb', 'randomized_benchmarking', 'allxy', 'standard_rb', 'filtered_rb']):
                categorized["Verification"].append(protocol)
            elif any(keyword in class_name or keyword in module_name 
                     for keyword in ['drag', 'calibration', 'optimization', 'tuning']):
                categorized["Calibration"].append(protocol)
            elif any(keyword in class_name or keyword in module_name 
                     for keyword in ['rabi', 'characterization']):
                categorized["Characterization"].append(protocol)
            else:
                categorized["Other"].append(protocol)
        
        # Remove empty categories
        categorized = {k: v for k, v in categorized.items() if v}
        
        return categorized
        
    except ImportError as e:
        print(f"Warning: Could not import qibocal.protocols: {e}")
        # Fallback to placeholder data if qibocal is not available
        return {
            "Characterization": [
                {"id": "resonator_spectroscopy", "name": "Resonator Spectroscopy"},
                {"id": "rabi_oscillations", "name": "Rabi Oscillations"}
            ],
            "Verification": [
                {"id": "allxy", "name": "AllXY"}
            ]
        }
    except Exception as e:
        print(f"Error discovering qibocal protocols: {e}")
        return {"Error": [{"id": "error", "name": f"Error loading protocols: {str(e)}"}]}

def iter_submodules(path, prefix=""):
    """Helper function to iterate over submodules"""
    try:
        import pkgutil
        for importer, modname, ispkg in pkgutil.iter_modules(path, prefix):
            yield type('ModuleInfo', (), {'name': modname})()
    except Exception:
        return

def get_available_qpu_list():
    """
    Get list of available QPU platforms from the qibolab platforms directory.
    """
    qrc_path = os.environ.get('QIBOLAB_PLATFORMS', os.path.join(root, 'qibolab_platforms_qrc'))
    qpus = []
    
    if os.path.exists(qrc_path):
        try:
            for qpu_name in os.listdir(qrc_path):
                qpu_path = os.path.join(qrc_path, qpu_name)
                if os.path.isdir(qpu_path) and not qpu_name.startswith('.'):
                    qpus.append(qpu_name)
        except OSError:
            pass
    
    # Fallback to default QPUs if directory doesn't exist or is empty
    if not qpus:
        qpus = ["qpu130", "qpu132"]
    
    return sorted(qpus)

@app.route("/api/qpu_parameters/<platform>")
def qpu_parameters(platform):
    """
    API endpoint to get parameters for a specific QPU.
    In the future, this will read from the platform's runcard.
    """
    # Placeholder data
    params = {
        "qpu130": {
            "qubits": {
                "0": {"readout_frequency": 6.021, "drive_amplitude": 0.5},
                "1": {"readout_frequency": 6.130, "drive_amplitude": 0.45},
                "2": {"readout_frequency": 6.245, "drive_amplitude": 0.52}
            }
        },
        "qpu132": {
            "qubits": {
                "0": {"readout_frequency": 7.011, "drive_amplitude": 0.6},
                "1": {"readout_frequency": 7.123, "drive_amplitude": 0.55}
            }
        }
    }
    
    platform_params = params.get(platform, {"qubits": {}})
    return jsonify(platform_params)

@app.route("/api/qpu_topology/<platform>")
def qpu_topology_visualization(platform):
    """
    API endpoint to generate topology visualization for a specific QPU.
    Returns a JSON response with base64-encoded PNG image of the topology.
    """
    qrc_path = os.environ.get('QIBOLAB_PLATFORMS', os.path.join(root, 'qibolab_platforms_qrc'))
    qpu_path = os.path.join(qrc_path, platform)
    
    if not os.path.exists(qpu_path):
        return jsonify({'error': 'QPU not found'}), 404
    
    # Get connectivity data and topology type
    connectivity_data = get_connectivity_data_from_qpu_config(qpu_path)
    topology_type = get_topology_from_qpu_config(qpu_path)
    
    if not connectivity_data:
        return jsonify({'error': 'No connectivity data found for this QPU'}), 404
    
    if topology_type == 'N/A' or topology_type == 'unknown':
        return jsonify({'error': 'Could not determine topology type'}), 404
    
    # Generate visualization
    img_base64 = generate_topology_visualization(connectivity_data, topology_type)
    
    if img_base64 is None:
        return jsonify({'error': 'Failed to generate topology visualization'}), 500
    
    return jsonify({
        'topology_type': topology_type,
        'num_qubits': len(set([q for conn in connectivity_data for q in conn[:2]])),
        'num_connections': len(connectivity_data),
        'image': img_base64
    })

if __name__ == '__main__':
    # Check inputs to the python call
    if len(sys.argv) > 1:
        port = sys.argv[1]
    
    bind = os.getenv('QD_BIND', host)
    port = os.getenv('QD_PORT', port)
    root = os.path.normpath(os.getenv('QD_PATH', root))
    key = os.getenv('QD_KEY')

    
    print('Quantum Dashboard Server running on http://{}:{}'.format(bind, port))
    print('Serving path: {}'.format(root))
    print('Authentication key: {}'.format(key))
    print('Press Ctrl+C to stop')
    app.run(bind, port, threaded=True, debug=False)
    sys.stdout.flush()
    # app.serve_forever()

    print('Quantum Dashboard Server stopped')
    sys.stdout.flush()
    sys.exit(0)
